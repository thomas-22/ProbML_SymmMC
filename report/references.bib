@misc{sommer2024connecting,
  author       = {Sommer, Emanuel and Wimmer, Lisa and Papamarkou, Theodore and Bothmann, Ludwig and Bischl, Bernd and R\"ugamer, David},
  title        = {Connecting the Dots: Is Mode-Connectedness the Key to Feasible Sample-Based Inference in Bayesian Neural Networks?},
  year         = {2024},
  eprint       = {2402.01484},
  eprinttype   = {arxiv},
  doi          = {10.48550/ARXIV.2402.01484},
  url          = {https://arxiv.org/abs/2402.01484}
}

@misc{wiese2023towards,
  author       = {Wiese, Jonas Gregor and Wimmer, Lisa and Papamarkou, Theodore and Bischl, Bernd and G\"unnemann, Stephan and R\"ugamer, David},
  title        = {Towards Efficient MCMC Sampling in Bayesian Neural Networks by Exploiting Symmetry},
  year         = {2023},
  eprint       = {2304.02902},
  eprinttype   = {arxiv},
  doi          = {10.48550/ARXIV.2304.02902},
  url          = {https://arxiv.org/abs/2304.02902}
}

@misc{hoffman2011nuts,
  author       = {Hoffman, Matthew D. and Gelman, Andrew},
  title        = {The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo},
  year         = {2011},
  eprint       = {1111.4246},
  eprinttype   = {arxiv},
  url          = {https://arxiv.org/abs/1111.4246}
}

@misc{izmailov2021posteriors,
  author       = {Izmailov, Pavel and Vikram, Sharad and Hoffman, Matthew D. and Wilson, Andrew Gordon},
  title        = {What Are Bayesian Neural Network Posteriors Really Like?},
  year         = {2021},
  eprint       = {2104.14421},
  eprinttype   = {arxiv},
  url          = {https://arxiv.org/abs/2104.14421}
}

@misc{garipov2018loss,
  author       = {Garipov, Timur and Izmailov, Pavel and Podoprikhin, Dmitrii and Vetrov, Dmitry and Wilson, Andrew Gordon},
  title        = {Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs},
  year         = {2018},
  eprint       = {1802.10026},
  eprinttype   = {arxiv},
  url          = {https://arxiv.org/abs/1802.10026}
}

@misc{fort2019deep,
  author       = {Fort, Stanislav and Hu, Huiyi and Lakshminarayanan, Balaji},
  title        = {Deep Ensembles: A Loss Landscape Perspective},
  year         = {2019},
  eprint       = {1912.02757},
  eprinttype   = {arxiv},
  url          = {https://arxiv.org/abs/1912.02757}
}

@misc{ovadia2019can,
  author       = {Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, D. and Nowozin, Sebastian and Dillon, Joshua V. and Lakshminarayanan, Balaji and Snoek, Jasper},
  title        = {Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift},
  year         = {2019},
  eprint       = {1906.02530},
  eprinttype   = {arxiv},
  url          = {https://arxiv.org/abs/1906.02530}
}

@misc{tiulpin2021greedy,
  author       = {Tiulpin, Aleksei and Blaschko, Matthew B.},
  title        = {Greedy Bayesian Posterior Approximation with Deep Ensembles},
  year         = {2021},
  eprint       = {2105.14275},
  eprinttype   = {arxiv},
  howpublished = {Transactions on Machine Learning Research},
  url          = {https://arxiv.org/abs/2105.14275}
}

@misc{gal2016dropout,
  author       = {Gal, Yarin and Ghahramani, Zoubin},
  title        = {Dropout as a Bayesian Approximation: Representing Model Uncertainty in Deep Learning},
  year         = {2016},
  eprint       = {1506.02142},
  eprinttype   = {arxiv},
  url          = {https://arxiv.org/abs/1506.02142}
}

@article{hornik1989multilayer,
  author       = {Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
  title        = {Multilayer Feedforward Networks Are Universal Approximators},
  journal      = {Neural Networks},
  volume       = {2},
  number       = {5},
  pages        = {359--366},
  year         = {1989},
  doi          = {10.1016/0893-6080(89)90020-8},
  url          = {https://www.sciencedirect.com/science/article/pii/0893608089900208}
}

@book{neal1996bayesian,
  author       = {Neal, Radford M.},
  title        = {Bayesian Learning for Neural Networks},
  series       = {Lecture Notes in Statistics},
  volume       = {118},
  publisher    = {Springer},
  address      = {New York, NY},
  year         = {1996}
}

@article{betancourt2017conceptual,
  author       = {Betancourt, Michael},
  title        = {A Conceptual Introduction to Hamiltonian Monte Carlo},
  journal      = {arXiv preprint arXiv:1701.02434},
  year         = {2017},
  doi          = {10.48550/ARXIV.1701.02434},
  url          = {https://arxiv.org/abs/1701.02434}
}

@misc{lakshminarayanan2016simple,
  author       = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  title        = {Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles},
  year         = {2016},
  eprint       = {1612.01474},
  eprinttype   = {arxiv},
  url          = {https://arxiv.org/abs/1612.01474}
}

@inbook{bishop2006approximate,
  author       = {Bishop, Christopher M.},
  title        = {Approximate Inference},
  booktitle    = {Pattern Recognition and Machine Learning},
  publisher    = {Springer},
  address      = {New York, NY},
  year         = {2006},
  chapter      = {5}
}

@incollection{gelman2013single,
  author       = {Gelman, Andrew and Carlin, John B. and Stern, Hal S. and Dunson, David B. and Vehtari, Aki and Rubin, Donald B.},
  title        = {Single-Parameter Models},
  booktitle    = {Bayesian Data Analysis},
  edition      = {3},
  publisher    = {Chapman \& Hall/CRC},
  address      = {Boca Raton, FL},
  year         = {2013},
  chapter      = {2},
  pages        = {27--60}
}

@inproceedings{kendall2017uncertainties,
  author       = {Kendall, Alex and Gal, Yarin},
  title        = {What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?},
  booktitle    = {Advances in Neural Information Processing Systems},
  volume       = {30},
  pages        = {5574--5584},
  year         = {2017},
  url          = {https://arxiv.org/abs/1703.04977}
}

@article{hullermeier2019aleatoric,
  author       = {H\"ullermeier, Eyke and Waegeman, Willem},
  title        = {Aleatoric and Epistemic Uncertainty in Machine Learning: An Introduction to Concepts and Methods},
  journal      = {Machine Learning},
  volume       = {110},
  number       = {3},
  pages        = {457--506},
  year         = {2019},
  doi          = {10.1007/s10994-021-05946-3},
  url          = {https://arxiv.org/abs/1910.09457}
}
